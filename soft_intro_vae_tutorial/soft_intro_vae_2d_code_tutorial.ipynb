{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV6UBste86Wf"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/dusk/64/000000/code.png\" style=\"height:50px;display:inline\"> Soft-IntroVAE Code Tutorial - 2D Datasets\n",
        "---\n",
        "\n",
        "Tal Daniel\n",
        "\n",
        "\n",
        "<center>\n",
        "    <a href=\"https://colab.research.google.com/github/taldatech/soft-intro-vae-pytorch/blob/main/soft_intro_vae_tutorial/soft_intro_vae_2d_code_tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "</center>\n",
        "\n",
        "* Paper: [**Soft-IntroVAE: Analyzing and Improving the Introspective Variational Autoencoder**, Tal Daniel and Aviv Tamar](https://arxiv.org/abs/2012.13253)\n",
        "* GitHub: <a href=\"https://github.com/taldatech/soft-intro-vae-pytorch\">soft-intro-vae-pytorch</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chMIzgAe86Wf"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/96/000000/loading.png\" style=\"height:50px;display:inline\"> Running Instructions\n",
        "---\n",
        "* This Jupyter Notebook can be opened locally with Anaconda, or online via Google Colab.\n",
        "* To run online, go to https://colab.research.google.com/ and drag-and-drop the `soft_intro_vae_2d_code_tutorial.ipynb` file.\n",
        "    * On Colab, note the \"directory\" icon on the left, figures and checkpoints are saved in this directory.\n",
        "* To run the training on the image dataset, it is better to have a GPU. In Google Cola select `Runtime->Change runtime type->GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TabRetvA86Wf"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
        "---\n",
        "* [Variational Autoencoders (VAEs)](#-Variational-Autoencoders-(VAEs))\n",
        "* [Soft-IntroVAE Objectives](#-Soft-IntroVAE-Objectives)\n",
        "* [2D Inference and Sampling Experiments](#-2D-Inference-and-Sampling-Experiments)\n",
        "    * [2D Experiments - Datsets and Architectures](#2D-Experiments---Datsets-and-Architectures)\n",
        "    * [2D Experiments - Algorithm and Train Function](#2D-Experiments---Algorithm-and-Train-Function)\n",
        "* [More Tutorials](#-But-Wait,-There-is-More...)\n",
        "* [Credits](#-Credits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-cbn2GOCyjK"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/plasticine/100/000000/epsilon.png\" style=\"height:50px;display:inline\"> Variational Autoencoders (VAEs)\n",
        "---\n",
        "Unlike regular autoencoders, Variational Autoencoder (VAE, <a href=\"https://arxiv.org/abs/1312.6114\">Kingma & Welling, 2014</a>) map the input to a distribution.\n",
        "\n",
        "In VAE we infer $p_{\\theta}(z|X)$ using a method calld **Variational Inference (VI)** (hence the name **Variational** Autoencoder).\n",
        "\n",
        "**Variational Inference (VI)** - solve an optimization problem in which we model $p_{\\theta}(z|X)$ using a simpler distribution, $q_{\\phi}(z|x)$, which is easier to evaluate, like a Gaussian, and **minimize the difference between these distributions using the KL-divergence**.\n",
        "\n",
        "**Evidence Lower BOund (ELBO)** - the optimization problem is to make the simpler distribution, $q_{\\phi}(z|X)$ as closer as possible to $p_{\\theta}(z|X)$. Using the KL-divergence, the we get the evidence lower bound: $$ \\log p_{\\theta}(X) \\geq \\mathbb{E}_{q_{\\phi}(z|X)}[\\log p_{\\theta}(X|z)] - D_{KL}[q_{\\phi}(z|X) || p(z)] = ELBO(X; \\theta, \\phi).$$\n",
        "\n",
        "$p(z)$ is a prior, independent of the model. In VAE, a common choice for the prior is a simple one $$p(z) \\sim \\mathcal{N}(0,1).$$\n",
        "\n",
        "$q_{\\phi}(z|X)$ is also called the **encoder** and $p_{\\theta}(X|z)$ the **decoder**.\n",
        "\n",
        "In practice, the ELBO is decomposed to the **reconstruction error** and the KL-divergence, which has a closed-form solution in the Gaussian case.\n",
        "\n",
        "The optimization is made possible thanks to the **reparameterization trick**, as it allows to backpropagate the gradients through the stochastic latent variable: $$ z \\sim q_{\\phi}(z|X) = \\mathcal{N}(z; \\mu, \\sigma^2 I) $$ $$ \\to z = \\mu + \\sigma \\odot \\epsilon, \\text{where } \\epsilon \\sim \\mathcal{N}(0, I) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhtWldR1CyjK"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/taldatech/soft-intro-vae-web/main/assets/vae_lilian_weng_lilianweng.github.io.png\" style=\"height:300px\">\n",
        "\n",
        "* <a href=\"https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html#beta-vae\">Image by Lilian Weng</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftp9TaC986Wf"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/fluent/96/000000/rubiks-cube.png\" style=\"height:50px;display:inline\"> Soft-IntroVAE Objectives\n",
        "---\n",
        "In Soft-IntroVAE, the encoder and decoder are trained to maximize the ELBO for real data (as in standard VAEs), and in addition, we use the exponential of the ELBO (expELBO) to \"push away\" fake data, generated by the decoder, from the latent space learned by the encoder, while the decoder also tries to pull back its generated data closer to the latent space, hence improving over time.\n",
        "\n",
        "Comparing to GANs, the discriminatory signal comes from the encoder (the ELBO acts as an energy function), thus, the VAE is trained in an introspective manner (no need for an additional discriminator).\n",
        "\n",
        "The objective of Soft-IntroVAE is written as follows:\n",
        "\n",
        "$$ \\mathcal{L}_{E_{\\phi}}(x,z) = s \\cdot(\\beta_{rec}\\mathcal{L}_r(x) +\\beta_{kl}KL(x)) + \\frac{1}{2}\\exp(-2s\\cdot (\\beta_{rec}\\mathcal{L}_r(D_{\\theta}(z)) + \\beta_{neg}KL(D_{\\theta}(z)))), $$\n",
        "$$ \\mathcal{L}_{D_{\\theta}}(x,z) = s \\cdot \\beta_{rec}\\mathcal{L}_r(x) +s \\cdot(\\beta_{kl}KL(D_{\\theta}(z)) +\\gamma_r \\cdot \\beta_{rec}\\mathcal{L}_r(D_{\\theta}(z))), $$\n",
        "\n",
        "where $\\mathcal{L}_r(x) = - \\mathbb{E}_{q_{\\phi}(z\\mid x)}\\left[\\log p_{\\theta}(x \\mid z)\\right]$ denotes the reconstruction error, $s$ is a scaling constant which is set to the inverse of the input dimensions, and $\\beta_{rec}, \\beta_{kl}, \\beta_{neg}$ and $\\gamma_r$ are hyperparameters. \n",
        "\n",
        "Note that in all our experiments the \"coeffecient of fake data reconstruction error\", $\\gamma_r = 1e-8$ (in the bootstrap version in can be set to 1), as setting it to higher values may hold back the decoder and slow down convergence (since at the beginning, the generated data is really bad). Basically, this hyperparamter can be annealed to 1 over time, but for simplicity, we don't do it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foxC6VBJCyjM"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/taldatech/soft-intro-vae-web/main/assets/sintrovae_flow.PNG\" style=\"height:350px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "89yXzsav86Wf"
      },
      "outputs": [],
      "source": [
        "# imports for the tutorial\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCJaJidi86Wf"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/bubbles/50/000000/average-value.png\" style=\"height:50px;display:inline\"> 2D Inference and Sampling Experiments\n",
        "---\n",
        "In this part, we will demonstrate Soft-IntroVAE on 2D distributions datasets. We begin with defining the datasets and architectures. You can skip this part and move straight to the training and results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbTjcUzN86Wf"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/dusk/64/000000/venn-diagram.png\" style=\"height:50px;display:inline\">2D Experiments - Datsets and Architectures\n",
        "---\n",
        "This part defines the building blocks of the Soft-IntroVAE and the 2D datsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fjVv7Bpz86Wf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "2D Datasets\n",
        "\"\"\"\n",
        "class ToyDataset:\n",
        "    def __init__(self, distr='8Gaussians', dim=2, scale=2, iter_per_mode=100):\n",
        "        self.distr = distr\n",
        "        self.dim = dim\n",
        "        self.scale = scale\n",
        "\n",
        "        self.dataset = []\n",
        "        for i in range(100000 // 25):\n",
        "            for x in range(-2, 3):\n",
        "                for y in range(-2, 3):\n",
        "                    point = np.random.randn(2) * 0.05\n",
        "                    point[0] += 2 * x\n",
        "                    point[1] += 2 * y\n",
        "                    self.dataset.append(point)\n",
        "        self.dataset = np.array(self.dataset, dtype='float32')\n",
        "        np.random.shuffle(self.dataset)\n",
        "        self.dataset /= 2.828  # stdev\n",
        "\n",
        "        self.range = 1\n",
        "        if self.distr == '25Gaussians':\n",
        "            self.range = 2\n",
        "\n",
        "        self.curr_iter = 0\n",
        "        self.curr_mode = 0\n",
        "        self.iter_per_mode = iter_per_mode\n",
        "\n",
        "    def next_batch(self, batch_size=64, device=None, sig=0.02):\n",
        "        dist_1 = ['2spirals', 'checkerboard', 'rings']\n",
        "        if self.distr in dist_1:\n",
        "            return sample_2d_data(self.distr, batch_size).to(device)\n",
        "        else:\n",
        "            if self.distr == '8Gaussians':\n",
        "                centers = [\n",
        "                    (1, 0),\n",
        "                    (-1, 0),\n",
        "                    (0, 1),\n",
        "                    (0, -1),\n",
        "                    (1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
        "                    (1. / np.sqrt(2), -1. / np.sqrt(2)),\n",
        "                    (-1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
        "                    (-1. / np.sqrt(2), -1. / np.sqrt(2))\n",
        "                ]\n",
        "                centers = [(self.scale * x, self.scale * y) for x, y in centers]\n",
        "                dataset = []\n",
        "                for i in range(batch_size):\n",
        "                    point = np.random.randn(2) * sig\n",
        "                    center = random.choice(centers)\n",
        "                    point[0] += center[0]\n",
        "                    point[1] += center[1]\n",
        "                    dataset.append(point)\n",
        "                dataset = np.array(dataset, dtype='float32')\n",
        "                dataset /= 1.414  # stdev\n",
        "\n",
        "                return torch.FloatTensor(dataset).to(device)\n",
        "\n",
        "            if self.distr == '25Gaussians':\n",
        "                batch_idx = np.random.randint(100000 // batch_size)\n",
        "                return torch.FloatTensor(self.dataset[batch_idx * batch_size:(batch_idx + 1) * batch_size]).to(\n",
        "                    device) * self.scale\n",
        "\n",
        "            if self.distr == 'Sequential8Gaussians':\n",
        "                centers = [\n",
        "                    (1, 0),\n",
        "                    (-1, 0),\n",
        "                    (0, 1),\n",
        "                    (0, -1),\n",
        "                    (1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
        "                    (1. / np.sqrt(2), -1. / np.sqrt(2)),\n",
        "                    (-1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
        "                    (-1. / np.sqrt(2), -1. / np.sqrt(2))\n",
        "                ]\n",
        "                centers = [(self.scale * x, self.scale * y) for x, y in centers]\n",
        "                dataset = []\n",
        "                for i in range(batch_size):\n",
        "                    point = np.random.randn(2) * .02\n",
        "                    center = centers[self.curr_mode]  # random.choice(centers)\n",
        "                    point[0] += center[0]\n",
        "                    point[1] += center[1]\n",
        "                    dataset.append(point)\n",
        "                dataset = np.array(dataset, dtype='float32')\n",
        "                dataset /= 1.414  # stdev\n",
        "                if self.curr_iter % self.iter_per_mode == self.iter_per_mode - 1:\n",
        "                    self.curr_mode += 1\n",
        "                    self.curr_mode %= 8\n",
        "                self.curr_iter += 1\n",
        "\n",
        "                return torch.FloatTensor(dataset).to(device)\n",
        "\n",
        "\n",
        "def sample_2d_data(dataset, n_samples):\n",
        "    \"\"\"\n",
        "    https://github.com/kamenbliznashki/normalizing_flows/blob/master/bnaf.py\n",
        "    :param dataset:\n",
        "    :param n_samples:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    z = torch.randn(n_samples, 2)\n",
        "\n",
        "    if dataset == '8gaussians':\n",
        "        scale = 4\n",
        "        sq2 = 1 / np.sqrt(2)\n",
        "        centers = [(1, 0), (-1, 0), (0, 1), (0, -1), (sq2, sq2), (-sq2, sq2), (sq2, -sq2), (-sq2, -sq2)]\n",
        "        centers = torch.tensor([(scale * x, scale * y) for x, y in centers])\n",
        "        return sq2 * (0.5 * z + centers[torch.randint(len(centers), size=(n_samples,))])\n",
        "\n",
        "    elif dataset == '2spirals':\n",
        "        n = torch.sqrt(torch.rand(n_samples // 2)) * 540 * (2 * np.pi) / 360\n",
        "        d1x = - torch.cos(n) * n + torch.rand(n_samples // 2) * 0.5\n",
        "        d1y = torch.sin(n) * n + torch.rand(n_samples // 2) * 0.5\n",
        "        x = torch.cat([torch.stack([d1x, d1y], dim=1),\n",
        "                       torch.stack([-d1x, -d1y], dim=1)], dim=0) / 3\n",
        "        return x + 0.1 * z\n",
        "\n",
        "    elif dataset == 'checkerboard':\n",
        "        x1 = torch.rand(n_samples) * 4 - 2\n",
        "        x2_ = torch.rand(n_samples) - torch.randint(0, 2, (n_samples,), dtype=torch.float) * 2\n",
        "        x2 = x2_ + x1.floor() % 2\n",
        "        return torch.stack([x1, x2], dim=1) * 2\n",
        "\n",
        "    elif dataset == 'rings':\n",
        "        n_samples4 = n_samples3 = n_samples2 = n_samples // 4\n",
        "        n_samples1 = n_samples - n_samples4 - n_samples3 - n_samples2\n",
        "\n",
        "        # so as not to have the first point = last point, set endpoint=False in np; here shifted by one\n",
        "        linspace4 = torch.linspace(0, 2 * np.pi, n_samples4 + 1)[:-1]\n",
        "        linspace3 = torch.linspace(0, 2 * np.pi, n_samples3 + 1)[:-1]\n",
        "        linspace2 = torch.linspace(0, 2 * np.pi, n_samples2 + 1)[:-1]\n",
        "        linspace1 = torch.linspace(0, 2 * np.pi, n_samples1 + 1)[:-1]\n",
        "\n",
        "        circ4_x = torch.cos(linspace4)\n",
        "        circ4_y = torch.sin(linspace4)\n",
        "        circ3_x = torch.cos(linspace4) * 0.75\n",
        "        circ3_y = torch.sin(linspace3) * 0.75\n",
        "        circ2_x = torch.cos(linspace2) * 0.5\n",
        "        circ2_y = torch.sin(linspace2) * 0.5\n",
        "        circ1_x = torch.cos(linspace1) * 0.25\n",
        "        circ1_y = torch.sin(linspace1) * 0.25\n",
        "\n",
        "        x = torch.stack([torch.cat([circ4_x, circ3_x, circ2_x, circ1_x]),\n",
        "                         torch.cat([circ4_y, circ3_y, circ2_y, circ1_y])], dim=1) * 3.0\n",
        "\n",
        "        # random sample\n",
        "        x = x[torch.randint(0, n_samples, size=(n_samples,))]\n",
        "\n",
        "        # Add noise\n",
        "        return x + torch.normal(mean=torch.zeros_like(x), std=0.08 * torch.ones_like(x))\n",
        "\n",
        "    else:\n",
        "        raise RuntimeError('Invalid `dataset` to sample from.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_yIS_WOf86Wf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Helper Functions\n",
        "\"\"\"\n",
        "def reparameterize(mu, logvar):\n",
        "    \"\"\"\n",
        "    This function applies the reparameterization trick:\n",
        "    z = mu(X) + sigma(X)^0.5 * epsilon, where epsilon ~ N(0,I)\n",
        "    :param mu: mean of x\n",
        "    :param logvar: log variaance of x\n",
        "    :return z: the sampled latent variable\n",
        "    \"\"\"\n",
        "    device = mu.device\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std).to(device)\n",
        "    return mu + eps * std\n",
        "\n",
        "def load_model(model, pretrained):\n",
        "    weights = torch.load(pretrained)\n",
        "    pretrained_dict = weights['model']\n",
        "    model.load_state_dict(pretrained_dict)\n",
        "    model_dict = model.state_dict()\n",
        "    \n",
        "\n",
        "def save_checkpoint(model, epoch, iteration, prefix=\"\"):\n",
        "    model_out_path = \"./saves/\" + prefix + \"model_epoch_{}_iter_{}.pth\".format(epoch, iteration)\n",
        "    state = {\"epoch\": epoch, \"model\": model.state_dict()}\n",
        "    if not os.path.exists(\"./saves/\"):\n",
        "        os.makedirs(\"./saves/\")\n",
        "\n",
        "    torch.save(state, model_out_path)\n",
        "\n",
        "    print(\"model checkpoint saved @ {}\".format(model_out_path))\n",
        "\n",
        "\n",
        "def setup_grid(range_lim=4, n_pts=1000, device=torch.device(\"cpu\")):\n",
        "    x = torch.linspace(-range_lim, range_lim, n_pts)\n",
        "    xx, yy = torch.meshgrid((x, x))\n",
        "    zz = torch.stack((xx.flatten(), yy.flatten()), dim=1)\n",
        "    return xx, yy, zz.to(device)\n",
        "\n",
        "\n",
        "def format_ax(ax, range_lim):\n",
        "    ax.set_xlim(-range_lim, range_lim)\n",
        "    ax.set_ylim(-range_lim, range_lim)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.invert_yaxis()\n",
        "    \n",
        "    \n",
        "def plot_vae_density(model, ax, test_grid, n_pts, batch_size, colorbar=False, beta_kl=1.0,\n",
        "                     beta_recon=1.0, set_title=True, device=torch.device('cpu')):\n",
        "    \"\"\" plots square grid and vae density \"\"\"\n",
        "    model.eval()\n",
        "    xx, yy, zz = test_grid\n",
        "    # compute posterior approx density\n",
        "    # p(x) = E_{z~p(z)}[q(z|x)]\n",
        "    zzk = []\n",
        "    with torch.no_grad():\n",
        "        for zz_i in zz.split(batch_size, dim=0):\n",
        "                zz_i = zz_i.to(device)\n",
        "                mu, logvar, _, rec = model(zz_i, deterministic=True)\n",
        "                recon_error = calc_reconstruction_loss(zz_i, rec, loss_type='mse', reduction='none')\n",
        "                while len(recon_error.shape) > 1:\n",
        "                    recon_error = recon_error.sum(-1)\n",
        "                kl = calc_kl(logvar=logvar, mu=mu, reduce=\"none\")\n",
        "                zzk_i = -1.0 * (beta_kl * kl + beta_recon * recon_error)\n",
        "                zzk += [zzk_i.exp()]\n",
        "    p_x = torch.cat(zzk, 0)\n",
        "    # plot\n",
        "    cmesh = ax.pcolormesh(xx.data.cpu().numpy(), yy.data.cpu().numpy(), p_x.view(n_pts, n_pts).data.cpu().numpy(),\n",
        "                          cmap=plt.cm.jet)\n",
        "    ax.set_facecolor(plt.cm.jet(0.))\n",
        "    if set_title:\n",
        "        ax.set_title('VAE density')\n",
        "    if colorbar:\n",
        "        plt.colorbar(cmesh)\n",
        "        \n",
        "        \n",
        "def calc_reconstruction_loss(x, recon_x, loss_type='mse', reduction='sum'):\n",
        "    \"\"\"\n",
        "\n",
        "    :param x: original inputs\n",
        "    :param recon_x:  reconstruction of the VAE's input\n",
        "    :param loss_type: \"mse\", \"l1\", \"bce\", \"gaussian\"\n",
        "    :param reduction: \"sum\", \"mean\", \"none\"\n",
        "    :return: recon_loss\n",
        "    \"\"\"\n",
        "    recon_x = recon_x.view(x.size(0), -1)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    if reduction not in ['sum', 'mean', 'none']:\n",
        "        raise NotImplementedError\n",
        "    if loss_type == 'mse':\n",
        "        recon_error = F.mse_loss(recon_x, x, reduction='none')\n",
        "        recon_error = recon_error.sum(1)\n",
        "        if reduction == 'sum':\n",
        "            recon_error = recon_error.sum()\n",
        "        elif reduction == 'mean':\n",
        "            recon_error = recon_error.mean()\n",
        "    elif loss_type == 'l1':\n",
        "        recon_error = F.l1_loss(recon_x, x, reduction=reduction)\n",
        "    elif loss_type == 'bce':\n",
        "        recon_error = F.binary_cross_entropy(recon_x, x, reduction=reduction)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return recon_error\n",
        "\n",
        "\n",
        "def calc_kl(logvar, mu, mu_o=10, is_outlier=False, reduce='sum'):\n",
        "    \"\"\"\n",
        "    Calculate kl-divergence\n",
        "    :param logvar: log-variance from the encoder\n",
        "    :param mu: mean from the encoder\n",
        "    :param mu_o: negative mean for outliers (hyper-parameter)\n",
        "    :param is_outlier: if True, calculates with mu_neg\n",
        "    :param reduce: type of reduce: 'sum', 'none'\n",
        "    :return: kld\n",
        "    \"\"\"\n",
        "    if is_outlier:\n",
        "        kl = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp() + 2 * mu * mu_o - mu_o.pow(2)).sum(1)\n",
        "    else:\n",
        "        kl = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp()).sum(1)\n",
        "    if reduce == 'sum':\n",
        "        kl = torch.sum(kl)\n",
        "    elif reduce == 'mean':\n",
        "        kl = torch.mean(kl)\n",
        "    return kl\n",
        "\n",
        "\n",
        "def plot_samples_density(dataset, model, scale, device):\n",
        "    \"\"\"\n",
        "    Plot real data from dataset, generated samples from model and density estimation\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    fig = plt.figure(figsize=(18, 6))\n",
        "    ax1 = fig.add_subplot(1, 3, 1)\n",
        "    plot_batch = dataset.next_batch(batch_size=1024, device=device)\n",
        "    plot_batch = plot_batch.data.cpu().numpy()\n",
        "    ax1.scatter(plot_batch[:, 0], plot_batch[:, 1], s=8, label=\"true dist\")\n",
        "    ax1.set_xlim((-scale * 2, scale * 2))\n",
        "    ax1.set_ylim((-scale * 2, scale * 2))\n",
        "    ax1.set_axis_off()\n",
        "    ax1.set_title('Real Data')\n",
        "     \n",
        "    ax2 = fig.add_subplot(1, 3, 2)\n",
        "    noise_batch = torch.randn(size=(1024, model.zdim)).to(device)\n",
        "    plot_fake_batch = model.sample(noise_batch)\n",
        "    plot_fake_batch = plot_fake_batch.data.cpu().numpy()\n",
        "    ax2.scatter(plot_fake_batch[:, 0], plot_fake_batch[:, 1], s=8, c='g', label=\"fake\")\n",
        "    ax2.set_xlim((-scale * 2, scale * 2))\n",
        "    ax2.set_ylim((-scale * 2, scale * 2))\n",
        "    ax2.set_axis_off()\n",
        "    ax2.set_title('Fake Samples')\n",
        "    \n",
        "    ax3 = fig.add_subplot(1, 3, 3)\n",
        "    test_grid = setup_grid(range_lim=scale * 2, n_pts=1024, device=torch.device('cpu'))\n",
        "    plot_vae_density(model, ax3, test_grid, n_pts=1024, batch_size=256, colorbar=False,\n",
        "                     beta_kl=1.0, beta_recon=1.0, set_title=False, device=device)\n",
        "    ax3.set_axis_off()\n",
        "    ax3.set_title(\"Density Estimation\")\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lJxs3gqd86Wf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Models\n",
        "\"\"\"\n",
        "\n",
        "class EncoderSimple(nn.Module):\n",
        "    def __init__(self, x_dim=2, zdim=2, n_layers=2, num_hidden=64):\n",
        "        super(EncoderSimple, self).__init__()\n",
        "\n",
        "        self.xdim = x_dim\n",
        "        self.zdim = zdim\n",
        "        self.n_layer = n_layers\n",
        "        self.num_hidden = num_hidden\n",
        "        self.main = nn.Sequential()\n",
        "        self.main.add_module('input', nn.Linear(x_dim, num_hidden))\n",
        "        self.main.add_module('act0', nn.ReLU(True))\n",
        "        for i in range(n_layers):\n",
        "            self.main.add_module('hidden_%d' % (i + 1), nn.Linear(num_hidden, num_hidden))\n",
        "            self.main.add_module('act_%d' % (i + 1), nn.ReLU(True))\n",
        "        self.main.add_module('output', nn.Linear(num_hidden, zdim * 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.main(x).view(x.size(0), -1)\n",
        "        mu, logvar = y.chunk(2, dim=1)\n",
        "        return mu, logvar\n",
        "\n",
        "\n",
        "class DecoderSimple(nn.Module):\n",
        "    def __init__(self, x_dim=2, zdim=2, n_layers=2, num_hidden=64):\n",
        "        super(DecoderSimple, self).__init__()\n",
        "\n",
        "        self.xdim = x_dim\n",
        "        self.zdim = zdim\n",
        "        self.n_layer = n_layers\n",
        "        self.num_hidden = num_hidden\n",
        "        self.loggamma = nn.Parameter(torch.tensor(0.0))\n",
        "        self.main = nn.Sequential()\n",
        "\n",
        "        self.main.add_module('input', nn.Linear(zdim, num_hidden))\n",
        "        self.main.add_module('act0', nn.ReLU(True))\n",
        "        for i in range(n_layers):\n",
        "            self.main.add_module('hidden_%d' % (i + 1), nn.Linear(num_hidden, num_hidden))\n",
        "            self.main.add_module('act_%d' % (i + 1), nn.ReLU(True))\n",
        "        self.main.add_module('output', nn.Linear(num_hidden, x_dim))\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = z.view(z.size(0), -1)\n",
        "        return self.main(z)\n",
        "\n",
        "\n",
        "class SoftIntroVAESimple(nn.Module):\n",
        "    def __init__(self, x_dim=2, zdim=2, n_layers=2, num_hidden=64):\n",
        "        super(SoftIntroVAESimple, self).__init__()\n",
        "\n",
        "        self.xdim = x_dim\n",
        "        self.zdim = zdim\n",
        "        self.n_layer = n_layers\n",
        "        self.num_hidden = num_hidden\n",
        "\n",
        "        self.encoder = EncoderSimple(x_dim, zdim, n_layers, num_hidden)\n",
        "\n",
        "        self.decoder = DecoderSimple(x_dim, zdim, n_layers, num_hidden)\n",
        "\n",
        "    def forward(self, x, deterministic=False):\n",
        "        mu, logvar = self.encode(x)\n",
        "        if deterministic:\n",
        "            z = mu\n",
        "        else:\n",
        "            z = reparameterize(mu, logvar)\n",
        "        y = self.decode(z)\n",
        "        return mu, logvar, z, y\n",
        "\n",
        "    def sample(self, z):\n",
        "        y = self.decode(z)\n",
        "        return y\n",
        "\n",
        "    def sample_with_noise(self, num_samples=1, device=torch.device(\"cpu\")):\n",
        "        z = torch.randn(num_samples, self.zdim).to(device)\n",
        "        return self.decode(z)\n",
        "\n",
        "    def encode(self, x):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def decode(self, z):\n",
        "        y = self.decoder(z)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHzZBLGD86Wf"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/loading-bar.png\" style=\"height:50px;display:inline\">2D Experiments - Algorithm and Train Function\n",
        "---\n",
        "This part defines the training algorithm of Soft-IntroVAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IyH6XGVw86Wf"
      },
      "outputs": [],
      "source": [
        "def train_soft_intro_vae_toy(z_dim=2, lr_e=2e-4, lr_d=2e-4, batch_size=32, n_iter=30000, num_vae=0, \n",
        "                             save_interval=1, recon_loss_type=\"mse\", beta_kl=1.0, beta_rec=1.0,\n",
        "                             beta_neg=1.0, test_iter=5000, seed=-1, pretrained=None, scale=1,\n",
        "                             device=torch.device(\"cpu\"), dataset=\"8Gaussians\", gamma_r=1e-8):\n",
        "    if seed != -1:\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(\"random seed: \", seed)\n",
        "\n",
        "    # --------------build models -------------------------\n",
        "    train_set = ToyDataset(distr=dataset)\n",
        "    scale *= train_set.range  # the scale of the 2d grid ([-1, 1] for Gaussians, [-2, 2] for the rest)\n",
        "\n",
        "    model = SoftIntroVAESimple(x_dim=2, zdim=z_dim, n_layers=3, num_hidden=256).to(device)\n",
        "    if pretrained is not None:\n",
        "        load_model(model, pretrained)\n",
        "    print(model)\n",
        "\n",
        "    optimizer_e = optim.Adam(model.encoder.parameters(), lr=lr_e)\n",
        "    optimizer_d = optim.Adam(model.decoder.parameters(), lr=lr_d)\n",
        "\n",
        "    milestones = (10000, 15000)\n",
        "    e_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_e, milestones=milestones, gamma=0.1)\n",
        "    d_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_d, milestones=milestones, gamma=0.1)\n",
        "\n",
        "    start_time = time.time()\n",
        "    dim_scale = 0.5  # normalizing factor, 's' in the paper\n",
        "\n",
        "    for it in range(n_iter):\n",
        "        batch = train_set.next_batch(batch_size=batch_size, device=device)\n",
        "        # save models\n",
        "        if it % save_interval == 0 and it > 0:\n",
        "            save_epoch = (it // save_interval) * save_interval\n",
        "            save_checkpoint(model, save_epoch, it, '')\n",
        "\n",
        "        model.train()\n",
        "        # --------------train----------------\n",
        "        if it < num_vae:\n",
        "            # vanilla VAE training, optimizeing the ELBO for both encoder and decoder\n",
        "            batch_size = batch.size(0)\n",
        "\n",
        "            real_batch = batch.to(device)\n",
        "\n",
        "            # =========== Update E, D ================\n",
        "            real_mu, real_logvar, z, rec = model(real_batch)\n",
        "\n",
        "            loss_rec = calc_reconstruction_loss(real_batch, rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
        "            loss_kl = calc_kl(real_logvar, real_mu, reduce=\"mean\")\n",
        "            loss = beta_rec * loss_rec + beta_kl * loss_kl\n",
        "\n",
        "            optimizer_e.zero_grad()\n",
        "            optimizer_d.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_e.step()\n",
        "            optimizer_d.step()\n",
        "\n",
        "            if it % test_iter == 0:\n",
        "                info = \"\\nIter: {}/{} : time: {:4.4f}: \".format(it, n_iter, time.time() - start_time)\n",
        "                info += 'Rec: {:.4f}, KL: {:.4f} '.format(loss_rec.data.cpu(), loss_kl.data.cpu())\n",
        "                print(info)\n",
        "        else:\n",
        "            # soft-intro-vae training\n",
        "            if len(batch.size()) == 3:\n",
        "                batch = batch.unsqueeze(0)\n",
        "\n",
        "            b_size = batch.size(0)\n",
        "\n",
        "            # generate random noise to produce 'fake' later\n",
        "            noise_batch = torch.randn(size=(b_size, z_dim)).to(device)\n",
        "            real_batch = batch.to(device)\n",
        "\n",
        "            # =========== Update E ================\n",
        "            for param in model.encoder.parameters():\n",
        "                param.requires_grad = True\n",
        "            for param in model.decoder.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "            # generate 'fake' data\n",
        "            fake = model.sample(noise_batch)\n",
        "            # optimize for real data\n",
        "            real_mu, real_logvar = model.encode(real_batch)\n",
        "            z = reparameterize(real_mu, real_logvar)\n",
        "            rec = model.decoder(z)  # reconstruction\n",
        "            # we also want to see what is the reconstruction error from mu\n",
        "            _, _, _, rec_det = model(real_batch, deterministic=True)\n",
        "\n",
        "            loss_rec = calc_reconstruction_loss(real_batch, rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
        "            # reconstruction error from mu (not optimized, only to observe)\n",
        "            loss_rec_det = calc_reconstruction_loss(real_batch, rec_det.detach(), loss_type=recon_loss_type,\n",
        "                                                    reduction=\"mean\")\n",
        "\n",
        "            # KLD loss for the real data\n",
        "            lossE_real_kl = calc_kl(real_logvar, real_mu, reduce=\"mean\")\n",
        "\n",
        "            # prepare the fake data for the expELBO\n",
        "            fake_mu, fake_logvar, z_fake, rec_fake = model(fake.detach())\n",
        "            # we also consider the reconstructions as 'fake' data, as they are output of the decoder\n",
        "            rec_mu, rec_logvar, z_rec, rec_rec = model(rec.detach())\n",
        "            \n",
        "            # KLD loss for the fake data\n",
        "            fake_kl_e = calc_kl(fake_logvar, fake_mu, reduce=\"none\")\n",
        "            rec_kl_e = calc_kl(rec_logvar, rec_mu, reduce=\"none\")\n",
        "            \n",
        "            # reconstruction loss for the fake data\n",
        "            loss_fake_rec = calc_reconstruction_loss(fake, rec_fake, loss_type=recon_loss_type, reduction=\"none\")\n",
        "            loss_rec_rec = calc_reconstruction_loss(rec, rec_rec, loss_type=recon_loss_type, reduction=\"none\")\n",
        "            \n",
        "            # expELBO\n",
        "            exp_elbo_fake = (-2 * dim_scale * (beta_rec * loss_fake_rec + beta_neg * fake_kl_e)).exp().mean()\n",
        "            exp_elbo_rec = (-2 * dim_scale * (beta_rec * loss_rec_rec + beta_neg * rec_kl_e)).exp().mean()\n",
        "            \n",
        "            # total loss\n",
        "            lossE = dim_scale * (beta_kl * lossE_real_kl + beta_rec * loss_rec) + 0.25 * (exp_elbo_fake + exp_elbo_rec)\n",
        "            \n",
        "            optimizer_e.zero_grad()\n",
        "            lossE.backward()\n",
        "            optimizer_e.step()\n",
        "\n",
        "            # ========= Update D ==================\n",
        "            for param in model.encoder.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in model.decoder.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "            # generate fake\n",
        "            fake = model.sample(noise_batch)\n",
        "            rec = model.decoder(z.detach())\n",
        "            # ELBO loss for real -- just the reconstruction, KLD for real doesn't affect the decoder\n",
        "            loss_rec = calc_reconstruction_loss(real_batch, rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
        "            \n",
        "            # prepare fake data for ELBO\n",
        "            rec_mu, rec_logvar = model.encode(rec)\n",
        "            z_rec = reparameterize(rec_mu, rec_logvar)\n",
        "            \n",
        "            fake_mu, fake_logvar = model.encode(fake)\n",
        "            z_fake = reparameterize(fake_mu, fake_logvar)\n",
        "\n",
        "            rec_rec = model.decode(z_rec.detach())\n",
        "            rec_fake = model.decode(z_fake.detach())\n",
        "\n",
        "            loss_rec_rec = calc_reconstruction_loss(rec.detach(), rec_rec, loss_type=recon_loss_type, reduction=\"mean\")\n",
        "            loss_rec_fake = calc_reconstruction_loss(fake.detach(), rec_fake, loss_type=recon_loss_type, reduction=\"mean\")\n",
        "\n",
        "            fake_kl = calc_kl(fake_logvar, fake_mu, reduce=\"mean\")\n",
        "            rec_kl = calc_kl(rec_logvar, rec_mu, reduce=\"mean\")\n",
        "\n",
        "            lossD = beta_rec * loss_rec + 0.5 * beta_kl * (fake_kl + rec_kl) + \\\n",
        "                            gamma_r * 0.5 * beta_rec * (loss_rec_rec + loss_rec_fake)\n",
        "            lossD = dim_scale * lossD\n",
        "\n",
        "            optimizer_d.zero_grad()\n",
        "            lossD.backward()\n",
        "            optimizer_d.step()\n",
        "            \n",
        "            if it % test_iter == 0:\n",
        "                info = \"\\nIter: {}/{} : time: {:4.4f}: \".format(it, n_iter, time.time() - start_time)\n",
        "\n",
        "                info += 'Rec: {:.4f} ({:.4f}), '.format(loss_rec.data.cpu(), loss_rec_det.data.cpu())\n",
        "                info += 'Kl_E: {:.4f}, expELBO_R: {:.4f}, expELBO_F: {:.4f}, '.format(lossE_real_kl.data.cpu(),\n",
        "                                                                                exp_elbo_rec.data.cpu(),\n",
        "                                                                                exp_elbo_fake.cpu())\n",
        "                info += 'Kl_F: {:.4f}, KL_R: {:.4f},'.format(fake_kl.data.cpu(), rec_kl.data.cpu())\n",
        "                info += ' DIFF_Kl_F: {:.4f}'.format(-lossE_real_kl.data.cpu() + fake_kl.data.cpu())\n",
        "\n",
        "                print(info)\n",
        "\n",
        "            if torch.isnan(lossE) or torch.isnan(lossD):\n",
        "                plt.close('all')\n",
        "                raise SystemError(\"loss is NaN.\")\n",
        "        e_scheduler.step()\n",
        "        d_scheduler.step()\n",
        "\n",
        "        if it % test_iter == 0 and it > 0 or it == n_iter - 1:\n",
        "            print(\"plotting...\")\n",
        "            model.eval()\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "            noise_batch = torch.randn(size=(1024, z_dim)).to(device)\n",
        "            plot_fake_batch = model.sample(noise_batch)\n",
        "            plot_fake_batch = plot_fake_batch.data.cpu().numpy()\n",
        "            ax.scatter(plot_fake_batch[:, 0], plot_fake_batch[:, 1], s=8, c='g', label=\"fake\")\n",
        "            ax.set_xlim((-scale * 2, scale * 2))\n",
        "            ax.set_ylim((-scale * 2, scale * 2))\n",
        "            ax.set_axis_off()\n",
        "            f_name = dataset + \"_bkl_\" + str(beta_kl) + \"_bneg_\" + str(beta_neg) + \"_brec_\" + str(\n",
        "                    beta_rec) + \"_seed_\" + str(seed) + \"_iter_\" + str(it) + \".png\"\n",
        "            plt.savefig(f_name, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            if it == n_iter - 1:\n",
        "                f_name = dataset + \"_bkl_\" + str(beta_kl) + \"_bneg_\" + str(beta_neg) + \"_brec_\" + str(\n",
        "                        beta_rec) + \"_seed_\" + str(seed) + \"_iter_\" + str(it) + \"_real.png\"\n",
        "                fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "                plot_batch = train_set.next_batch(batch_size=1024, device=device)\n",
        "                plot_batch = plot_batch.data.cpu().numpy()\n",
        "                ax.scatter(plot_batch[:, 0], plot_batch[:, 1], s=8, label=\"true dist\")\n",
        "                ax.set_xlim((-scale * 2, scale * 2))\n",
        "                ax.set_ylim((-scale * 2, scale * 2))\n",
        "                ax.set_axis_off()\n",
        "                plt.savefig(f_name, bbox_inches='tight')\n",
        "                plt.close()\n",
        "                f_name = dataset + \"_bkl_\" + str(beta_kl) + \"_bneg_\" + str(beta_neg) + \"_brec_\" + str(\n",
        "                        beta_rec) + \"_seed_\" + str(seed) + \"_iter_\" + str(it) + \".png\"\n",
        "                print(\"plotting density...\")\n",
        "                fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "                test_grid = setup_grid(range_lim=scale * 2, n_pts=1024, device=torch.device('cpu'))\n",
        "                plot_vae_density(model, ax, test_grid, n_pts=1024, batch_size=256, colorbar=False,\n",
        "                                 beta_kl=1.0, beta_recon=1.0, set_title=False, device=device)\n",
        "                ax.set_axis_off()\n",
        "                f_name = \"density_\" + f_name\n",
        "                plt.savefig(f_name, bbox_inches='tight')\n",
        "                plt.close()\n",
        "            model.train()\n",
        "    plot_samples_density(train_set, model, scale, device)\n",
        "    plt.show()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FICDRVhj86Wf",
        "outputId": "df2ce059-4aa8-481a-bcbc-d65ebcbd17d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# hyperparameters\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "seed = 92  # for reproducible results\n",
        "datasets = ['8Gaussians', '2spirals', 'checkerboard', 'rings']\n",
        "chosen_hyperparmas = {'8Gaussians': {'b_kl': 0.3, 'b_neg': 0.9, 'b_rec': 0.2},\n",
        "                      '2spirals': {'b_kl': 0.5, 'b_neg': 1.0, 'b_rec': 0.2},\n",
        "                      'checkerboard': {'b_kl': 0.1, 'b_neg': 0.2, 'b_rec': 0.2},\n",
        "                      'rings': {'b_kl': 0.2, 'b_neg': 1.0, 'b_rec': 0.2}}\n",
        "num_iter = 30_000\n",
        "lr = 2e-4\n",
        "batch_size = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5I4iaefu86Wg",
        "outputId": "81c111d0-0dfc-483b-cdee-4fd0715a6c17",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random seed:  92\n",
            "SoftIntroVAESimple(\n",
            "  (encoder): EncoderSimple(\n",
            "    (main): Sequential(\n",
            "      (input): Linear(in_features=2, out_features=256, bias=True)\n",
            "      (act0): ReLU(inplace=True)\n",
            "      (hidden_1): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (act_1): ReLU(inplace=True)\n",
            "      (hidden_2): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (act_2): ReLU(inplace=True)\n",
            "      (hidden_3): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (act_3): ReLU(inplace=True)\n",
            "      (output): Linear(in_features=256, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder): DecoderSimple(\n",
            "    (main): Sequential(\n",
            "      (input): Linear(in_features=2, out_features=256, bias=True)\n",
            "      (act0): ReLU(inplace=True)\n",
            "      (hidden_1): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (act_1): ReLU(inplace=True)\n",
            "      (hidden_2): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (act_2): ReLU(inplace=True)\n",
            "      (hidden_3): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (act_3): ReLU(inplace=True)\n",
            "      (output): Linear(in_features=256, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "Iter: 0/30000 : time: 3.0525: Rec: 2.0007, KL: 0.0035 \n",
            "model checkpoint saved @ ./saves/model_epoch_5000_iter_5000.pth\n",
            "\n",
            "Iter: 5000/30000 : time: 77.6562: Rec: 0.3310 (0.0005), Kl_E: 1.6037, expELBO_R: 0.2131, expELBO_F: 0.2072, Kl_F: 1.8805, KL_R: 1.7409, DIFF_Kl_F: 0.2768\n",
            "plotting...\n",
            "model checkpoint saved @ ./saves/model_epoch_10000_iter_10000.pth\n",
            "\n",
            "Iter: 10000/30000 : time: 173.1318: Rec: 0.4395 (0.0007), Kl_E: 1.5409, expELBO_R: 0.2304, expELBO_F: 0.2321, Kl_F: 1.5829, KL_R: 1.5733, DIFF_Kl_F: 0.0420\n",
            "plotting...\n",
            "model checkpoint saved @ ./saves/model_epoch_15000_iter_15000.pth\n",
            "\n",
            "Iter: 15000/30000 : time: 272.0904: Rec: 0.3836 (0.0005), Kl_E: 1.5266, expELBO_R: 0.2350, expELBO_F: 0.2349, Kl_F: 1.5418, KL_R: 1.5440, DIFF_Kl_F: 0.0152\n",
            "plotting...\n",
            "model checkpoint saved @ ./saves/model_epoch_20000_iter_20000.pth\n",
            "\n",
            "Iter: 20000/30000 : time: 369.4844: Rec: 0.3814 (0.0004), Kl_E: 1.5501, expELBO_R: 0.2302, expELBO_F: 0.2326, Kl_F: 1.5569, KL_R: 1.5629, DIFF_Kl_F: 0.0068\n",
            "plotting...\n",
            "model checkpoint saved @ ./saves/model_epoch_25000_iter_25000.pth\n",
            "\n",
            "Iter: 25000/30000 : time: 466.9435: Rec: 0.3930 (0.0004), Kl_E: 1.5309, expELBO_R: 0.2352, expELBO_F: 0.2337, Kl_F: 1.5768, KL_R: 1.5556, DIFF_Kl_F: 0.0458\n",
            "plotting...\n",
            "plotting...\n",
            "plotting density...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x432 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "dataset = datasets[0]\n",
        "beta_kl = chosen_hyperparmas[dataset]['b_kl']\n",
        "beta_neg = chosen_hyperparmas[dataset]['b_neg']\n",
        "beta_rec = chosen_hyperparmas[dataset]['b_rec']\n",
        "if dataset == '8Gaussians':\n",
        "    scale = 1\n",
        "else:\n",
        "    scale = 2\n",
        "    \n",
        "# train\n",
        "model = train_soft_intro_vae_toy(z_dim=2, lr_e=lr, lr_d=lr, batch_size=batch_size, n_iter=num_iter, num_vae=2000, \n",
        "                             save_interval=5000, recon_loss_type=\"mse\", beta_kl=beta_kl, beta_rec=beta_rec,\n",
        "                             beta_neg=beta_neg, test_iter=5000, seed=seed, scale=scale,\n",
        "                             device=device, dataset=dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuDRuyz2CyjS"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/nolan/64/more.png\" style=\"height:50px;display:inline\"> But Wait, There is More...\n",
        "---\n",
        "* Soft-IntroVAE Tutorials\n",
        "    * [Soft-IntroVAE for Images](https://github.com/taldatech/soft-intro-vae-pytorch/blob/main/soft_intro_vae_tutorial/soft_intro_vae_image_code_tutorial.ipynb)\n",
        "        * [Open in Colab](https://colab.research.google.com/github/taldatech/soft-intro-vae-pytorch/blob/main/soft_intro_vae_tutorial/soft_intro_vae_image_code_tutorial.ipynb)\n",
        "    * [Bootstrap Soft-IntroVAE](https://github.com/taldatech/soft-intro-vae-pytorch/blob/main/soft_intro_vae_tutorial/soft_intro_vae_bootstrap_code_tutorial.ipynb)\n",
        "        * [Open in Colab](https://colab.research.google.com/github/taldatech/soft-intro-vae-pytorch/blob/main/soft_intro_vae_tutorial/soft_intro_vae_bootstrap_code_tutorial.ipynb)\n",
        "* General Tutorials (Jupyter Notebooks with code)\n",
        "    * [CS236756 - Intro to Machine Learning](https://github.com/taldatech/cs236756-intro-to-ml)\n",
        "    * [EE046202 - Unsupervised Learning and Data Analysis](https://github.com/taldatech/ee046202-unsupervised-learning-data-analysis)\n",
        "    * [EE046746 - Computer Vision](https://github.com/taldatech/ee046746-computer-vision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I91ipV086Wg"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
        "---\n",
        "* Icons from <a href=\"https://icons8.com/\">Icon8.com</a> - https://icons8.com\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "soft_intro_vae_code_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}